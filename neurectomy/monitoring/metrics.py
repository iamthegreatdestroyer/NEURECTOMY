"""
Prometheus Metrics for Neurectomy API
Production monitoring with comprehensive metric collection
"""

from prometheus_client import Counter, Histogram, Gauge, Info
from functools import wraps
import time
from typing import Callable, Optional, Dict, Any
import logging

logger = logging.getLogger(__name__)


# ============================================================================
# HTTP Request Metrics
# ============================================================================

http_requests_total = Counter(
    'neurectomy_http_requests_total',
    'Total HTTP requests to Neurectomy API',
    ['method', 'endpoint', 'status'],
    help='Count of HTTP requests by method, endpoint, and status code'
)

http_request_duration_seconds = Histogram(
    'neurectomy_http_request_duration_seconds',
    'HTTP request latency in seconds',
    ['method', 'endpoint'],
    buckets=(0.01, 0.05, 0.1, 0.5, 1.0, 2.5, 5.0, 10.0),
    help='Request latency histogram with millisecond precision'
)

http_request_size_bytes = Histogram(
    'neurectomy_http_request_size_bytes',
    'HTTP request size in bytes',
    ['method', 'endpoint'],
    buckets=(100, 1000, 10000, 100000, 1000000),
)

http_response_size_bytes = Histogram(
    'neurectomy_http_response_size_bytes',
    'HTTP response size in bytes',
    ['method', 'endpoint'],
    buckets=(100, 1000, 10000, 100000, 1000000),
)


# ============================================================================
# Ryot LLM Integration Metrics
# ============================================================================

ryot_requests_total = Counter(
    'neurectomy_ryot_requests_total',
    'Total requests to Ryot LLM service',
    ['status'],  # success, error, timeout
    help='Count of Ryot LLM requests by status'
)

ryot_request_duration_seconds = Histogram(
    'neurectomy_ryot_request_duration_seconds',
    'Ryot LLM request latency in seconds',
    buckets=(0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0),
    help='Ryot LLM request latency with fine-grained buckets'
)

ryot_tokens_generated_total = Counter(
    'neurectomy_ryot_tokens_generated_total',
    'Total tokens generated by Ryot LLM',
    ['model'],
    help='Cumulative token count'
)

ryot_model_loading_duration_seconds = Gauge(
    'neurectomy_ryot_model_loading_duration_seconds',
    'Time to load Ryot LLM model in seconds',
    help='Model loading time (useful for startup metrics)'
)

ryot_batch_size = Histogram(
    'neurectomy_ryot_batch_size',
    'Batch size for Ryot LLM inference',
    buckets=(1, 2, 4, 8, 16, 32, 64),
)

ryot_gpu_memory_usage_bytes = Gauge(
    'neurectomy_ryot_gpu_memory_usage_bytes',
    'GPU memory usage by Ryot LLM in bytes',
)


# ============================================================================
# ΣLANG Compression Metrics
# ============================================================================

sigmalang_compression_requests_total = Counter(
    'neurectomy_sigmalang_compression_requests_total',
    'Total compression requests to ΣLANG',
    ['status'],
)

sigmalang_compression_ratio = Histogram(
    'neurectomy_sigmalang_compression_ratio',
    'ΣLANG compression ratio (original/compressed)',
    buckets=(5, 10, 15, 20, 25, 30, 50),
    help='Compression ratio: original_size / compressed_size'
)

sigmalang_compression_duration_seconds = Histogram(
    'neurectomy_sigmalang_compression_duration_seconds',
    'Time to compress data with ΣLANG',
    buckets=(0.001, 0.01, 0.1, 1.0, 10.0),
)

sigmalang_original_size_bytes = Histogram(
    'neurectomy_sigmalang_original_size_bytes',
    'Original data size before ΣLANG compression',
    buckets=(1000, 10000, 100000, 1000000, 10000000),
)

sigmalang_compressed_size_bytes = Histogram(
    'neurectomy_sigmalang_compressed_size_bytes',
    'Compressed data size after ΣLANG',
    buckets=(1000, 10000, 100000, 1000000, 10000000),
)

sigmalang_decompression_requests_total = Counter(
    'neurectomy_sigmalang_decompression_requests_total',
    'Total decompression requests to ΣLANG',
    ['status'],
)


# ============================================================================
# ΣVAULT Storage Metrics
# ============================================================================

sigmavault_operations_total = Counter(
    'neurectomy_sigmavault_operations_total',
    'Total operations on ΣVAULT storage',
    ['operation', 'status'],  # operation: store, retrieve, delete
    help='ΣVAULT operation counts'
)

sigmavault_operation_duration_seconds = Histogram(
    'neurectomy_sigmavault_operation_duration_seconds',
    'Duration of ΣVAULT storage operations',
    ['operation'],
    buckets=(0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0),
)

sigmavault_storage_bytes_total = Gauge(
    'neurectomy_sigmavault_storage_bytes_total',
    'Total bytes stored in ΣVAULT',
    help='Cumulative storage usage'
)

sigmavault_objects_total = Gauge(
    'neurectomy_sigmavault_objects_total',
    'Total objects stored in ΣVAULT',
    help='Number of stored objects'
)

sigmavault_encryption_duration_seconds = Histogram(
    'neurectomy_sigmavault_encryption_duration_seconds',
    'Time to encrypt data in ΣVAULT',
    buckets=(0.001, 0.01, 0.1, 1.0),
)

sigmavault_snapshot_operations_total = Counter(
    'neurectomy_sigmavault_snapshot_operations_total',
    'Total snapshot operations on ΣVAULT',
    ['operation', 'status'],  # operation: create, restore
)


# ============================================================================
# Circuit Breaker Metrics
# ============================================================================

circuit_breaker_state = Gauge(
    'neurectomy_circuit_breaker_state',
    'Circuit breaker state for service integration',
    ['service'],
    help='0=closed (healthy), 1=open (failing), 2=half-open (testing)'
)

circuit_breaker_failures = Counter(
    'neurectomy_circuit_breaker_failures_total',
    'Total failures in circuit breaker',
    ['service'],
)

circuit_breaker_state_changes = Counter(
    'neurectomy_circuit_breaker_state_changes_total',
    'Number of state transitions in circuit breaker',
    ['service', 'from_state', 'to_state'],
)


# ============================================================================
# Business Metrics
# ============================================================================

active_users = Gauge(
    'neurectomy_active_users',
    'Current number of active users',
    help='Real-time user activity metric'
)

tokens_generated_total = Counter(
    'neurectomy_tokens_generated_total',
    'Total tokens generated across all models',
    ['model'],
    help='Cumulative token generation'
)

api_keys_active = Gauge(
    'neurectomy_api_keys_active',
    'Number of active API keys',
)

requests_per_user = Histogram(
    'neurectomy_requests_per_user',
    'Requests per active user',
    buckets=(1, 10, 50, 100, 500, 1000),
)

cost_per_request = Gauge(
    'neurectomy_cost_per_request',
    'Estimated cost per API request in cents',
    ['endpoint'],
)


# ============================================================================
# System Metrics
# ============================================================================

system_info = Info(
    'neurectomy_system',
    'Neurectomy system information',
    help='Static system metadata'
)

build_info = Info(
    'neurectomy_build',
    'Neurectomy build information',
)


# ============================================================================
# ASGI Middleware
# ============================================================================

class MetricsMiddleware:
    """
    FastAPI/ASGI middleware for automatic HTTP metrics collection
    
    Tracks:
    - Request count by method, endpoint, status
    - Request latency distribution
    - Request/response sizes
    """
    
    def __init__(self, app):
        self.app = app
        
    async def __call__(self, scope, receive, send):
        if scope["type"] != "http":
            return await self.app(scope, receive, send)
        
        method = scope.get("method", "UNKNOWN")
        path = scope.get("path", "/")
        
        # Normalize path to avoid cardinality explosion
        # (e.g., /users/123 -> /users/{id})
        endpoint = self._normalize_path(path)
        
        start_time = time.time()
        request_size = 0
        
        # Calculate request size from headers
        headers = scope.get("headers", [])
        for header_name, header_value in headers:
            if header_name == b"content-length":
                try:
                    request_size = int(header_value.decode())
                except (ValueError, UnicodeDecodeError):
                    pass
        
        status_code = 500
        response_size = 0
        
        async def send_wrapper(message):
            nonlocal status_code, response_size
            
            if message["type"] == "http.response.start":
                status_code = message["status"]
                
                # Calculate response size from headers
                headers = message.get("headers", [])
                for header_name, header_value in headers:
                    if header_name == b"content-length":
                        try:
                            response_size = int(header_value.decode())
                        except (ValueError, UnicodeDecodeError):
                            pass
                
            await send(message)
        
        try:
            await self.app(scope, receive, send_wrapper)
        finally:
            # Record metrics
            duration = time.time() - start_time
            
            http_requests_total.labels(
                method=method,
                endpoint=endpoint,
                status=status_code
            ).inc()
            
            http_request_duration_seconds.labels(
                method=method,
                endpoint=endpoint
            ).observe(duration)
            
            if request_size > 0:
                http_request_size_bytes.labels(
                    method=method,
                    endpoint=endpoint
                ).observe(request_size)
            
            if response_size > 0:
                http_response_size_bytes.labels(
                    method=method,
                    endpoint=endpoint
                ).observe(response_size)
            
            logger.debug(
                f"HTTP {method} {endpoint} {status_code} {duration:.3f}s"
            )
    
    def _normalize_path(self, path: str) -> str:
        """Normalize path to avoid cardinality explosion"""
        # This is a simple implementation
        # In production, you might use more sophisticated path normalization
        if path.startswith("/v1/"):
            parts = path.split("/")
            if len(parts) > 2:
                # Keep first 3 parts: /v1/resource
                return "/".join(parts[:3])
        return path


# ============================================================================
# Decorators for Function-Level Metrics
# ============================================================================

def track_ryot_request(func: Callable):
    """
    Decorator to track Ryot LLM requests
    
    Usage:
        @track_ryot_request
        async def generate_text(prompt: str):
            pass
    """
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        status = "success"
        
        try:
            result = await func(*args, **kwargs)
            
            # Track tokens if available
            if hasattr(result, 'token_count'):
                model = kwargs.get('model', 'default')
                ryot_tokens_generated_total.labels(model=model).inc(
                    result.token_count
                )
            
            return result
        except TimeoutError:
            status = "timeout"
            raise
        except Exception as e:
            status = "error"
            logger.error(f"Ryot request error: {e}")
            raise
        finally:
            duration = time.time() - start_time
            ryot_requests_total.labels(status=status).inc()
            ryot_request_duration_seconds.observe(duration)
    
    return wrapper


def track_compression(func: Callable):
    """
    Decorator to track ΣLANG compression operations
    
    Usage:
        @track_compression
        async def compress_data(data: bytes):
            pass
    """
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        status = "success"
        
        try:
            result = await func(*args, **kwargs)
            
            # Track compression metrics if available
            if hasattr(result, 'original_size') and hasattr(result, 'compressed_size'):
                original_size = result.original_size
                compressed_size = result.compressed_size
                
                if compressed_size > 0:
                    ratio = original_size / compressed_size
                    sigmalang_compression_ratio.observe(ratio)
                
                sigmalang_original_size_bytes.observe(original_size)
                sigmalang_compressed_size_bytes.observe(compressed_size)
            
            return result
        except Exception as e:
            status = "error"
            logger.error(f"Compression error: {e}")
            raise
        finally:
            duration = time.time() - start_time
            sigmalang_compression_requests_total.labels(status=status).inc()
            sigmalang_compression_duration_seconds.observe(duration)
    
    return wrapper


def track_storage_operation(operation: str):
    """
    Decorator to track ΣVAULT storage operations
    
    Usage:
        @track_storage_operation("store")
        async def store_file(path: str, data: bytes):
            pass
    """
    def decorator(func: Callable):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            status = "success"
            
            try:
                result = await func(*args, **kwargs)
                return result
            except Exception as e:
                status = "error"
                logger.error(f"Storage operation {operation} error: {e}")
                raise
            finally:
                duration = time.time() - start_time
                
                sigmavault_operations_total.labels(
                    operation=operation,
                    status=status
                ).inc()
                
                sigmavault_operation_duration_seconds.labels(
                    operation=operation
                ).observe(duration)
        
        return wrapper
    return decorator


def track_circuit_breaker(service_name: str):
    """
    Decorator to track circuit breaker state transitions
    
    Usage:
        @track_circuit_breaker("ryot_llm")
        async def call_external_service():
            pass
    """
    def decorator(func: Callable):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            try:
                result = await func(*args, **kwargs)
                circuit_breaker_state.labels(service=service_name).set(0)  # Closed
                return result
            except Exception as e:
                circuit_breaker_failures.labels(service=service_name).inc()
                logger.error(f"Circuit breaker {service_name} failure: {e}")
                raise
        
        return wrapper
    return decorator


# ============================================================================
# Helper Functions
# ============================================================================

def set_active_users(count: int):
    """Update active user count"""
    active_users.set(count)


def increment_tokens_generated(model: str, count: int):
    """Increment tokens generated for a model"""
    tokens_generated_total.labels(model=model).inc(count)


def update_circuit_breaker_state(service: str, state: int):
    """
    Update circuit breaker state
    
    Args:
        service: Service name
        state: 0=closed (healthy), 1=open (failing), 2=half-open (testing)
    """
    circuit_breaker_state.labels(service=service).set(state)


def record_cost_per_request(endpoint: str, cost_cents: float):
    """Record cost per request for an endpoint"""
    cost_per_request.labels(endpoint=endpoint).set(cost_cents)
