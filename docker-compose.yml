# NEURECTOMY Docker Compose Configuration
# Development environment with all required services

version: "3.9"

services:
  # =============================================================================
  # Databases
  # =============================================================================

  postgres:
    image: pgvector/pgvector:pg16
    container_name: neurectomy-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-neurectomy}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-neurectomy}
      POSTGRES_DB: ${POSTGRES_DB:-neurectomy}
    ports:
      - "5434:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/postgres/init:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U neurectomy"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - neurectomy-network

  timescaledb:
    image: timescale/timescaledb:latest-pg16
    container_name: neurectomy-timescale
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-neurectomy}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-neurectomy}
      POSTGRES_DB: neurectomy_ts
    ports:
      - "5433:5432"
    volumes:
      - timescale_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U neurectomy"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - neurectomy-network

  neo4j:
    image: neo4j:5-community
    container_name: neurectomy-neo4j
    restart: unless-stopped
    environment:
      NEO4J_AUTH: neo4j/${NEO4J_PASSWORD:-neurectomy}
      NEO4J_PLUGINS: '["apoc", "graph-data-science"]'
      NEO4J_dbms_memory_pagecache_size: 512M
      NEO4J_dbms_memory_heap_max__size: 512M
    ports:
      - "7474:7474" # HTTP
      - "7687:7687" # Bolt
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7474"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - neurectomy-network

  # =============================================================================
  # Cache & Messaging
  # =============================================================================

  redis:
    image: redis:7-alpine
    container_name: neurectomy-redis
    restart: unless-stopped
    command: redis-server --appendonly yes
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - neurectomy-network

  nats:
    image: nats:2-alpine
    container_name: neurectomy-nats
    restart: unless-stopped
    command: ["--jetstream", "--store_dir", "/data"]
    ports:
      - "4222:4222" # Client
      - "8222:8222" # Monitoring
    volumes:
      - nats_data:/data
    healthcheck:
      test: ["CMD", "wget", "--spider", "http://localhost:8222/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - neurectomy-network

  # =============================================================================
  # AI/ML Services
  # =============================================================================

  ollama:
    image: ollama/ollama:latest
    container_name: neurectomy-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - neurectomy-network

  # =============================================================================
  # Observability
  # =============================================================================

  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: neurectomy-prometheus
    restart: unless-stopped
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.enable-lifecycle"
    ports:
      - "9090:9090"
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    networks:
      - neurectomy-network

  grafana:
    image: grafana/grafana:10.2.0
    container_name: neurectomy-grafana
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: neurectomy
      GF_USERS_ALLOW_SIGN_UP: false
    ports:
      - "3001:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker/grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
    networks:
      - neurectomy-network

  jaeger:
    image: jaegertracing/all-in-one:1.52
    container_name: neurectomy-jaeger
    restart: unless-stopped
    environment:
      COLLECTOR_OTLP_ENABLED: true
    ports:
      - "5775:5775/udp"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
      - "16686:16686" # UI
      - "14268:14268"
      - "14250:14250"
      - "9411:9411"
    networks:
      - neurectomy-network

  # =============================================================================
  # MLOps Services (Phase 2: Intelligence Layer)
  # =============================================================================

  mlflow:
    build:
      context: ./docker/mlflow
      dockerfile: Dockerfile
    container_name: neurectomy-mlflow
    restart: unless-stopped
    environment:
      MLFLOW_TRACKING_URI: http://0.0.0.0:5000
      MLFLOW_BACKEND_STORE_URI: postgresql://neurectomy:neurectomy@postgres:5432/mlflow
      MLFLOW_ARTIFACT_ROOT: /mlflow/artifacts
    command: >
      mlflow server
      --backend-store-uri postgresql://neurectomy:neurectomy@postgres:5432/mlflow
      --default-artifact-root /mlflow/artifacts
      --host 0.0.0.0
      --port 5000
    ports:
      - "5000:5000"
    volumes:
      - mlflow_artifacts:/mlflow/artifacts
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - neurectomy-network

  optuna-dashboard:
    image: ghcr.io/optuna/optuna-dashboard:latest
    container_name: neurectomy-optuna-dashboard
    restart: unless-stopped
    command: >
      optuna-dashboard postgresql://neurectomy:neurectomy@postgres:5432/optuna
      --host 0.0.0.0
      --port 8080
    ports:
      - "8085:8080"
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - neurectomy-network

  # ChromaDB for vector storage (alternative to pgvector for experimentation)
  chromadb:
    image: chromadb/chroma:latest
    container_name: neurectomy-chromadb
    restart: unless-stopped
    environment:
      CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER: chromadb.auth.token.TokenConfigServerAuthCredentialsProvider
      CHROMA_SERVER_AUTH_TOKEN_TRANSPORT_HEADER: X-Chroma-Token
      CHROMA_SERVER_AUTH_CREDENTIALS: ${CHROMA_TOKEN:-neurectomy-secret-token}
    ports:
      - "8001:8000"
    volumes:
      - chromadb_data:/chroma/chroma
    networks:
      - neurectomy-network

  # =============================================================================
  # NEURECTOMY ML Service
  # =============================================================================

  ml-service:
    build:
      context: ./services/ml-service
      dockerfile: Dockerfile
    container_name: neurectomy-ml-service
    restart: unless-stopped
    environment:
      ENVIRONMENT: production
      PORT: 8000
      DATABASE_URL: postgresql://neurectomy:neurectomy@postgres:5432/neurectomy
      REDIS_URL: redis://redis:6379
      MLFLOW_TRACKING_URI: http://mlflow:5000
      JWT_SECRET: ${JWT_SECRET:-neurectomy-jwt-secret-change-in-production}
      JWT_ALGORITHM: HS256
      JWT_ACCESS_TOKEN_EXPIRE_MINUTES: 30
      JWT_REFRESH_TOKEN_EXPIRE_DAYS: 7
      RATE_LIMIT_REQUESTS: 100
      RATE_LIMIT_WINDOW_SECONDS: 60
    ports:
      - "8002:8000"
    volumes:
      - ml_models:/app/models
      - ml_data:/app/data
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      mlflow:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - neurectomy-network

  # ML Service with GPU support (for training)
  ml-service-gpu:
    build:
      context: ./services/ml-service
      dockerfile: Dockerfile.gpu
    container_name: neurectomy-ml-service-gpu
    restart: unless-stopped
    environment:
      ENVIRONMENT: production
      PORT: 8000
      DATABASE_URL: postgresql://neurectomy:neurectomy@postgres:5432/neurectomy
      REDIS_URL: redis://redis:6379
      MLFLOW_TRACKING_URI: http://mlflow:5000
      JWT_SECRET: ${JWT_SECRET:-neurectomy-jwt-secret-change-in-production}
      CUDA_VISIBLE_DEVICES: 0
    ports:
      - "8003:8000"
    volumes:
      - ml_models:/app/models
      - ml_data:/app/data
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      mlflow:
        condition: service_healthy
    profiles:
      - gpu
    networks:
      - neurectomy-network

  # =============================================================================
  # NEURECTOMY Services (for production-like development)
  # =============================================================================

  # Uncomment to run backend in Docker instead of locally
  # rust-core:
  #   build:
  #     context: ./services/rust-core
  #     dockerfile: Dockerfile
  #   container_name: neurectomy-rust-core
  #   restart: unless-stopped
  #   environment:
  #     DATABASE_URL: postgresql://neurectomy:neurectomy@postgres:5432/neurectomy
  #     NEO4J_URI: bolt://neo4j:7687
  #     NEO4J_USER: neo4j
  #     NEO4J_PASSWORD: ${NEO4J_PASSWORD:-neurectomy}
  #     REDIS_URL: redis://redis:6379
  #     NATS_URL: nats://nats:4222
  #     RUST_LOG: debug
  #   ports:
  #     - "8080:8080"
  #   depends_on:
  #     postgres:
  #       condition: service_healthy
  #     neo4j:
  #       condition: service_healthy
  #     redis:
  #       condition: service_healthy
  #     nats:
  #       condition: service_healthy
  #   networks:
  #     - neurectomy-network

# =============================================================================
# Networks & Volumes
# =============================================================================

networks:
  neurectomy-network:
    driver: bridge
    name: neurectomy-network

volumes:
  postgres_data:
    name: neurectomy-postgres-data
  timescale_data:
    name: neurectomy-timescale-data
  neo4j_data:
    name: neurectomy-neo4j-data
  neo4j_logs:
    name: neurectomy-neo4j-logs
  redis_data:
    name: neurectomy-redis-data
  nats_data:
    name: neurectomy-nats-data
  ollama_data:
    name: neurectomy-ollama-data
  prometheus_data:
    name: neurectomy-prometheus-data
  grafana_data:
    name: neurectomy-grafana-data
  mlflow_artifacts:
    name: neurectomy-mlflow-artifacts
  chromadb_data:
    name: neurectomy-chromadb-data
  ml_models:
    name: neurectomy-ml-models
  ml_data:
    name: neurectomy-ml-data
