# NEURECTOMY Docker Compose Configuration
# Development environment with all required services

version: "3.9"

services:
  # =============================================================================
  # Databases
  # =============================================================================

  postgres:
    image: pgvector/pgvector:pg16
    container_name: neurectomy-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-neurectomy}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-neurectomy}
      POSTGRES_DB: ${POSTGRES_DB:-neurectomy}
    ports:
      - "5434:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/postgres/init:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U neurectomy"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - neurectomy-network

  timescaledb:
    image: timescale/timescaledb:latest-pg16
    container_name: neurectomy-timescale
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-neurectomy}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-neurectomy}
      POSTGRES_DB: neurectomy_ts
    ports:
      - "5433:5432"
    volumes:
      - timescale_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U neurectomy"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - neurectomy-network

  neo4j:
    image: neo4j:5-community
    container_name: neurectomy-neo4j
    restart: unless-stopped
    environment:
      NEO4J_AUTH: neo4j/${NEO4J_PASSWORD:-neurectomy}
      NEO4J_PLUGINS: '["apoc", "graph-data-science"]'
      NEO4J_dbms_memory_pagecache_size: 512M
      NEO4J_dbms_memory_heap_max__size: 512M
    ports:
      - "7474:7474" # HTTP
      - "7687:7687" # Bolt
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7474"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - neurectomy-network

  # =============================================================================
  # Cache & Messaging
  # =============================================================================

  redis:
    image: redis:7-alpine
    container_name: neurectomy-redis
    restart: unless-stopped
    command: redis-server --appendonly yes
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - neurectomy-network

  nats:
    image: nats:2-alpine
    container_name: neurectomy-nats
    restart: unless-stopped
    command: ["--jetstream", "--store_dir", "/data"]
    ports:
      - "4222:4222" # Client
      - "8222:8222" # Monitoring
    volumes:
      - nats_data:/data
    healthcheck:
      test: ["CMD", "wget", "--spider", "http://localhost:8222/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - neurectomy-network

  # =============================================================================
  # AI/ML Services
  # =============================================================================

  ollama:
    image: ollama/ollama:latest
    container_name: neurectomy-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - neurectomy-network

  # =============================================================================
  # Observability
  # =============================================================================

  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: neurectomy-prometheus
    restart: unless-stopped
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.enable-lifecycle"
    ports:
      - "9090:9090"
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./docker/prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml
      - prometheus_data:/prometheus
    depends_on:
      - alertmanager
    networks:
      - neurectomy-network

  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: neurectomy-alertmanager
    restart: unless-stopped
    command:
      - "--config.file=/etc/alertmanager/alertmanager.yml"
      - "--storage.path=/alertmanager"
      - "--web.external-url=http://localhost:9093"
    ports:
      - "9093:9093"
    volumes:
      - ./docker/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - ./docker/alertmanager/templates:/etc/alertmanager/templates
      - alertmanager_data:/alertmanager
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - neurectomy-network

  grafana:
    image: grafana/grafana:10.2.0
    container_name: neurectomy-grafana
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: neurectomy
      GF_USERS_ALLOW_SIGN_UP: false
    ports:
      - "3001:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker/grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
    networks:
      - neurectomy-network

  jaeger:
    image: jaegertracing/all-in-one:1.52
    container_name: neurectomy-jaeger
    restart: unless-stopped
    environment:
      COLLECTOR_OTLP_ENABLED: true
    ports:
      - "5775:5775/udp"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
      - "16686:16686" # UI
      - "14268:14268"
      - "14250:14250"
      - "9411:9411"
    networks:
      - neurectomy-network

  loki:
    image: grafana/loki:2.9.0
    container_name: neurectomy-loki
    restart: unless-stopped
    command: -config.file=/etc/loki/loki-config.yml
    ports:
      - "3100:3100"
    volumes:
      - ./docker/loki/loki-config.yml:/etc/loki/loki-config.yml
      - loki_data:/loki
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - neurectomy-network

  promtail:
    image: grafana/promtail:2.9.0
    container_name: neurectomy-promtail
    restart: unless-stopped
    command: -config.file=/etc/promtail/promtail-config.yml
    volumes:
      - ./docker/promtail/promtail-config.yml:/etc/promtail/promtail-config.yml
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/log:/var/log:ro
    depends_on:
      - loki
    networks:
      - neurectomy-network

  # =============================================================================
  # MLOps Services (Phase 2: Intelligence Layer)
  # =============================================================================

  # MinIO - S3-compatible object storage for MLflow artifacts
  minio:
    image: minio/minio:latest
    container_name: neurectomy-minio
    restart: unless-stopped
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000" # API
      - "9001:9001" # Console
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - neurectomy-network

  # MinIO Client - Create buckets on startup
  minio-client:
    image: minio/mc:latest
    container_name: neurectomy-minio-client
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set myminio http://minio:9000 minioadmin minioadmin;
      mc mb myminio/mlflow-artifacts --ignore-existing;
      mc mb myminio/optuna-artifacts --ignore-existing;
      mc anonymous set download myminio/mlflow-artifacts;
      mc anonymous set download myminio/optuna-artifacts;
      exit 0;
      "
    networks:
      - neurectomy-network

  mlflow:
    build:
      context: ./docker/mlflow
      dockerfile: Dockerfile
    image: neurectomy-mlflow:latest
    container_name: neurectomy-mlflow
    restart: unless-stopped
    environment:
      MLFLOW_TRACKING_URI: http://0.0.0.0:5000
      MLFLOW_BACKEND_STORE_URI: postgresql://mlflow:mlflow@postgres:5432/mlflow
      MLFLOW_ARTIFACT_ROOT: s3://mlflow-artifacts/
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
    command: >
      mlflow server
      --backend-store-uri postgresql://mlflow:mlflow@postgres:5432/mlflow
      --default-artifact-root s3://mlflow-artifacts/
      --host 0.0.0.0
      --port 5000
    ports:
      - "5000:5000"
    depends_on:
      postgres:
        condition: service_healthy
      minio:
        condition: service_healthy
      minio-client:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - neurectomy-network

  optuna-dashboard:
    image: ghcr.io/optuna/optuna-dashboard:latest
    container_name: neurectomy-optuna-dashboard
    restart: unless-stopped
    command: >
      optuna-dashboard postgresql://optuna:optuna@postgres:5432/optuna
      --host 0.0.0.0
      --port 8080
    ports:
      - "8085:8080"
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - neurectomy-network

  # ChromaDB for vector storage (alternative to pgvector for experimentation)
  chromadb:
    image: chromadb/chroma:latest
    container_name: neurectomy-chromadb
    restart: unless-stopped
    environment:
      CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER: chromadb.auth.token.TokenConfigServerAuthCredentialsProvider
      CHROMA_SERVER_AUTH_TOKEN_TRANSPORT_HEADER: X-Chroma-Token
      CHROMA_SERVER_AUTH_CREDENTIALS: ${CHROMA_TOKEN:-neurectomy-secret-token}
    ports:
      - "8001:8000"
    volumes:
      - chromadb_data:/chroma/chroma
    networks:
      - neurectomy-network

  # =============================================================================
  # NEURECTOMY ML Service (Intelligence Foundry)
  # =============================================================================

  ml-service:
    build:
      context: ./services/ml-service
      dockerfile: Dockerfile
    container_name: neurectomy-ml-service
    restart: unless-stopped
    environment:
      # Service Configuration
      SERVICE_NAME: intelligence-foundry-ml
      SERVICE_VERSION: 1.0.0
      HOST: 0.0.0.0
      PORT: 8000
      DEBUG: "false"

      # MLflow Configuration
      MLFLOW_TRACKING_URI: http://mlflow:5000
      MLFLOW_ARTIFACT_ROOT: s3://mlflow-artifacts/
      MLFLOW_BACKEND_STORE_URI: postgresql://mlflow:mlflow@postgres:5432/mlflow

      # Optuna Configuration
      OPTUNA_STORAGE: postgresql://optuna:optuna@postgres:5432/optuna
      OPTUNA_DEFAULT_SAMPLER: tpe
      OPTUNA_DEFAULT_PRUNER: median

      # MinIO/S3 Configuration
      S3_ENDPOINT_URL: http://minio:9000
      S3_ACCESS_KEY: minioadmin
      S3_SECRET_KEY: minioadmin
      S3_BUCKET: mlflow-artifacts
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000

      # PostgreSQL Configuration
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: mlflow
      POSTGRES_PASSWORD: mlflow
      POSTGRES_DB: mlflow

      # Training Defaults
      DEFAULT_BATCH_SIZE: 32
      DEFAULT_EPOCHS: 10
      DEFAULT_LEARNING_RATE: 0.001
      MAX_PARALLEL_TRIALS: 4
      GPU_MEMORY_FRACTION: 0.9

      # WebSocket Configuration
      WS_HEARTBEAT_INTERVAL: 30
      WS_MAX_CONNECTIONS: 100

      # CORS Configuration
      CORS_ORIGINS: http://localhost:5173,http://localhost:3000,http://localhost:8080,tauri://localhost,http://localhost:1420

      # Legacy support
      DATABASE_URL: postgresql://neurectomy:neurectomy@postgres:5432/neurectomy
      REDIS_URL: redis://redis:6379
    ports:
      - "8002:8000"
    volumes:
      - ./services/ml-service:/app
      - ml_service_cache:/root/.cache
      - ml_models:/app/models
      - ml_data:/app/data
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      mlflow:
        condition: service_healthy
      minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    networks:
      - neurectomy-network

  # ML Service with GPU support (for training)
  ml-service-gpu:
    build:
      context: ./services/ml-service
      dockerfile: Dockerfile.gpu
    container_name: neurectomy-ml-service-gpu
    restart: unless-stopped
    environment:
      ENVIRONMENT: production
      PORT: 8000
      DATABASE_URL: postgresql://neurectomy:neurectomy@postgres:5432/neurectomy
      REDIS_URL: redis://redis:6379
      MLFLOW_TRACKING_URI: http://mlflow:5000
      JWT_SECRET: ${JWT_SECRET:-neurectomy-jwt-secret-change-in-production}
      CUDA_VISIBLE_DEVICES: 0
    ports:
      - "8003:8000"
    volumes:
      - ml_models:/app/models
      - ml_data:/app/data
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      mlflow:
        condition: service_healthy
    profiles:
      - gpu
    networks:
      - neurectomy-network

  # =============================================================================
  # NEURECTOMY Services (for production-like development)
  # =============================================================================

  # Uncomment to run backend in Docker instead of locally
  # rust-core:
  #   build:
  #     context: ./services/rust-core
  #     dockerfile: Dockerfile
  #   container_name: neurectomy-rust-core
  #   restart: unless-stopped
  #   environment:
  #     DATABASE_URL: postgresql://neurectomy:neurectomy@postgres:5432/neurectomy
  #     NEO4J_URI: bolt://neo4j:7687
  #     NEO4J_USER: neo4j
  #     NEO4J_PASSWORD: ${NEO4J_PASSWORD:-neurectomy}
  #     REDIS_URL: redis://redis:6379
  #     NATS_URL: nats://nats:4222
  #     RUST_LOG: debug
  #   ports:
  #     - "8080:8080"
  #   depends_on:
  #     postgres:
  #       condition: service_healthy
  #     neo4j:
  #       condition: service_healthy
  #     redis:
  #       condition: service_healthy
  #     nats:
  #       condition: service_healthy
  #   networks:
  #     - neurectomy-network

# =============================================================================
# Networks & Volumes
# =============================================================================

networks:
  neurectomy-network:
    driver: bridge
    name: neurectomy-network

volumes:
  postgres_data:
    name: neurectomy-postgres-data
  timescale_data:
    name: neurectomy-timescale-data
  neo4j_data:
    name: neurectomy-neo4j-data
  neo4j_logs:
    name: neurectomy-neo4j-logs
  redis_data:
    name: neurectomy-redis-data
  nats_data:
    name: neurectomy-nats-data
  ollama_data:
    name: neurectomy-ollama-data
  prometheus_data:
    name: neurectomy-prometheus-data
  alertmanager_data:
    name: neurectomy-alertmanager-data
  grafana_data:
    name: neurectomy-grafana-data
  loki_data:
    name: neurectomy-loki-data
  minio_data:
    name: neurectomy-minio-data
  mlflow_artifacts:
    name: neurectomy-mlflow-artifacts
  chromadb_data:
    name: neurectomy-chromadb-data
  ml_models:
    name: neurectomy-ml-models
  ml_data:
    name: neurectomy-ml-data
  ml_service_cache:
    name: neurectomy-ml-service-cache
