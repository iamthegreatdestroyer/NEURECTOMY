{
  "annotations": {
    "list": [
      {
        "datasource": {
          "type": "prometheus",
          "uid": "prometheus"
        },
        "enable": true,
        "expr": "ALERTS{severity=\"critical\"}",
        "iconColor": "rgba(255, 96, 96, 1)",
        "name": "Critical Alerts",
        "step": "60s",
        "tagKeys": "alertname",
        "textFormat": "{{ alertname }}",
        "titleFormat": "Alert"
      }
    ]
  },
  "description": "Ryot LLM Service Metrics - Request latency, throughput, GPU utilization, token generation",
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 1,
  "id": 1,
  "links": [
    {
      "asDropdown": false,
      "icon": "star",
      "includeVars": true,
      "tags": [],
      "targetBlank": true,
      "title": "View Agent Collective",
      "tooltip": "Navigate to Agent Collective dashboard for task correlation",
      "type": "link",
      "url": "/d/agent-collective/agent-collective?${__url_time_range}"
    }
  ],
  "liveNow": false,
  "panels": [
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "description": "95th percentile request latency in milliseconds - warns at 500ms, critical at 1000ms",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "yellow", "value": 500 },
              { "color": "red", "value": 1000 }
            ]
          },
          "unit": "ms"
        }
      },
      "gridPos": { "h": 8, "w": 6, "x": 0, "y": 0 },
      "id": 2,
      "options": {
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "fields": "",
          "calcs": ["lastNotNull"]
        },
        "showThresholdLabels": false,
        "showThresholdMarkers": true
      },
      "pluginVersion": "10.2.0",
      "targets": [
        {
          "expr": "histogram_quantile(0.95, rate(neurectomy_ryot_request_duration_seconds_bucket[5m])) * 1000",
          "intervalFactor": 2,
          "legendFormat": "P95 Latency",
          "refId": "A"
        }
      ],
      "title": "Request Latency - P95",
      "type": "gauge"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "description": "99th percentile request latency - warns at 2000ms",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "yellow", "value": 2000 },
              { "color": "red", "value": 5000 }
            ]
          },
          "unit": "ms"
        }
      },
      "gridPos": { "h": 8, "w": 6, "x": 6, "y": 0 },
      "id": 3,
      "options": {
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "fields": "",
          "calcs": ["lastNotNull"]
        },
        "showThresholdLabels": false,
        "showThresholdMarkers": true
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.99, rate(neurectomy_ryot_request_duration_seconds_bucket[5m])) * 1000",
          "refId": "A"
        }
      ],
      "title": "Request Latency - P99",
      "type": "gauge"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "description": "Median (P50) request latency",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "yellow", "value": 200 },
              { "color": "red", "value": 500 }
            ]
          },
          "unit": "ms"
        }
      },
      "gridPos": { "h": 8, "w": 6, "x": 12, "y": 0 },
      "id": 4,
      "options": {
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "fields": "",
          "calcs": ["lastNotNull"]
        },
        "showThresholdLabels": false,
        "showThresholdMarkers": true
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.50, rate(neurectomy_ryot_request_duration_seconds_bucket[5m])) * 1000",
          "refId": "A"
        }
      ],
      "title": "Request Latency - P50",
      "type": "gauge"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "description": "Time to First Token (TTFT) distribution - latency for first token generation",
      "fieldConfig": {
        "defaults": {
          "custom": {
            "lineWidth": 2,
            "fillOpacity": 10
          },
          "color": {
            "mode": "palette-classic"
          }
        }
      },
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 8 },
      "id": 5,
      "options": {
        "legend": { "calcs": ["mean", "max"], "displayMode": "table" },
        "tooltip": { "mode": "multi" }
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.95, rate(neurectomy_ryot_ttft_seconds_bucket[5m]))",
          "legendFormat": "TTFT P95"
        },
        {
          "expr": "histogram_quantile(0.50, rate(neurectomy_ryot_ttft_seconds_bucket[5m]))",
          "legendFormat": "TTFT P50"
        }
      ],
      "title": "Time to First Token (TTFT) Distribution",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "description": "Token generation rate in tokens per second",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": { "lineWidth": 2 },
          "unit": "short"
        }
      },
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 8 },
      "id": 6,
      "options": {
        "legend": { "displayMode": "list" },
        "tooltip": { "mode": "multi" }
      },
      "targets": [
        {
          "expr": "rate(neurectomy_ryot_tokens_generated_total[1m])",
          "legendFormat": "Tokens/sec - {{ model }}"
        }
      ],
      "title": "Token Generation Rate",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "description": "GPU memory utilization percentage - warns at 90%",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "yellow", "value": 80 },
              { "color": "red", "value": 95 }
            ]
          },
          "unit": "percent"
        }
      },
      "gridPos": { "h": 6, "w": 6, "x": 0, "y": 16 },
      "id": 7,
      "options": {
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "fields": "",
          "calcs": ["lastNotNull"]
        },
        "showThresholdLabels": false,
        "showThresholdMarkers": true
      },
      "targets": [
        {
          "expr": "(neurectomy_ryot_gpu_memory_usage_bytes / neurectomy_ryot_gpu_memory_max_bytes) * 100",
          "legendFormat": "GPU Memory %"
        }
      ],
      "title": "GPU Memory Utilization",
      "type": "gauge"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "description": "Batch size distribution - P50, P95, P99 values",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" }
        }
      },
      "gridPos": { "h": 6, "w": 6, "x": 6, "y": 16 },
      "id": 8,
      "options": {
        "legend": { "displayMode": "table", "calcs": ["mean", "max"] },
        "tooltip": { "mode": "multi" }
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.95, rate(neurectomy_ryot_batch_size_bucket[5m]))",
          "legendFormat": "Batch Size P95"
        },
        {
          "expr": "histogram_quantile(0.50, rate(neurectomy_ryot_batch_size_bucket[5m]))",
          "legendFormat": "Batch Size P50"
        }
      ],
      "title": "Batch Size Distribution",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "description": "Request throughput in requests per minute",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "unit": "short"
        }
      },
      "gridPos": { "h": 6, "w": 6, "x": 12, "y": 16 },
      "id": 9,
      "options": {
        "legend": { "displayMode": "list" },
        "tooltip": { "mode": "multi" }
      },
      "targets": [
        {
          "expr": "rate(neurectomy_ryot_requests_total[1m])",
          "legendFormat": "Requests/min - {{ status }}"
        }
      ],
      "title": "Request Throughput",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "description": "Error rate percentage (5xx errors / total requests)",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "unit": "percent"
        }
      },
      "gridPos": { "h": 6, "w": 6, "x": 0, "y": 22 },
      "id": 10,
      "options": {
        "orientation": "auto",
        "reduceOptions": {
          "values": false,
          "fields": "",
          "calcs": ["lastNotNull"]
        },
        "showThresholdLabels": false,
        "showThresholdMarkers": true
      },
      "targets": [
        {
          "expr": "(rate(neurectomy_ryot_requests_total{status=\"error\"}[5m]) / rate(neurectomy_ryot_requests_total[5m])) * 100",
          "legendFormat": "Error Rate %"
        }
      ],
      "thresholds": {
        "mode": "absolute",
        "steps": [
          { "color": "green", "value": null },
          { "color": "yellow", "value": 1 },
          { "color": "red", "value": 5 }
        ]
      },
      "title": "Error Rate",
      "type": "gauge"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "description": "GPU Out of Memory indicators - alerts when memory pressure exceeds threshold",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" }
        }
      },
      "gridPos": { "h": 6, "w": 6, "x": 6, "y": 22 },
      "id": 11,
      "options": {
        "legend": { "displayMode": "list" },
        "tooltip": { "mode": "multi" }
      },
      "targets": [
        {
          "expr": "neurectomy_ryot_gpu_oom_errors_total",
          "legendFormat": "OOM Errors - {{ gpu_id }}"
        }
      ],
      "title": "GPU OOM Incidents",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus"
      },
      "description": "Model inference speedup ratio (baseline vs optimized)",
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "unit": "short"
        }
      },
      "gridPos": { "h": 6, "w": 6, "x": 12, "y": 22 },
      "id": 12,
      "options": {
        "legend": { "displayMode": "table", "calcs": ["mean"] },
        "tooltip": { "mode": "multi" }
      },
      "targets": [
        {
          "expr": "avg(neurectomy_ryot_baseline_latency_ms / neurectomy_ryot_optimized_latency_ms) by (model)",
          "legendFormat": "Speedup - {{ model }}"
        }
      ],
      "title": "Model Optimization Speedup",
      "type": "timeseries"
    }
  ],
  "refresh": "30s",
  "schemaVersion": 38,
  "style": "dark",
  "tags": ["phase-18", "ryot", "llm", "tier-2"],
  "templating": {
    "list": [
      {
        "current": {
          "selected": false,
          "text": "production",
          "value": "production"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "prometheus"
        },
        "definition": "label_values(neurectomy_ryot_requests_total, environment)",
        "description": null,
        "hide": 0,
        "includeAll": false,
        "label": "Environment",
        "multi": false,
        "name": "environment",
        "options": [],
        "query": {
          "query": "label_values(neurectomy_ryot_requests_total, environment)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 0,
        "type": "query"
      },
      {
        "current": {
          "selected": false,
          "text": "All",
          "value": "$__all"
        },
        "datasource": {
          "type": "prometheus",
          "uid": "prometheus"
        },
        "definition": "label_values(neurectomy_ryot_requests_total, model)",
        "description": null,
        "hide": 0,
        "includeAll": true,
        "label": "Model",
        "multi": true,
        "name": "model",
        "options": [],
        "query": {
          "query": "label_values(neurectomy_ryot_requests_total, model)",
          "refId": "StandardVariableQuery"
        },
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "sort": 0,
        "type": "query"
      }
    ]
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "browser",
  "title": "Dashboard 1: Ryot LLM Metrics",
  "uid": "ryot-llm-metrics",
  "version": 1,
  "weekStart": ""
}
