[tool.poetry]
name = "neurectomy-ml-service"
version = "0.2.0"
description = "Machine Learning & AI Service for NEURECTOMY - Intelligence Foundry"
authors = ["NEURECTOMY Team"]
license = "Proprietary"
readme = "README.md"
packages = [{include = "src"}]

[tool.poetry.dependencies]
python = "^3.11"
fastapi = "^0.109.0"
uvicorn = {extras = ["standard"], version = "^0.27.0"}
pydantic = "^2.5.0"
pydantic-settings = "^2.1.0"

# Database
sqlalchemy = "^2.0.25"
asyncpg = "^0.30.0"
redis = "^5.0.1"
pgvector = "^0.2.4"

# ML/AI - PyTorch 2.5+ required for torch.compile() and modern AMP
# @TENSOR - Pin to 2.5+ for torch.compile(), torch.amp.autocast(), torch.inference_mode()
torch = "^2.5.0"
torchvision = "^0.20.0"
torchaudio = "^2.5.0"
transformers = "^4.45.0"
sentence-transformers = "^3.2.0"
scikit-learn = "^1.5.0"
numpy = "^2.0.0"
pandas = "^2.2.0"

# LLM Integration
openai = "^1.50.0"
anthropic = "^0.37.0"
ollama = "^0.3.0"
tiktoken = "^0.8.0"

# vLLM for production inference (optional, requires CUDA)
# vllm = "^0.6.0"

# MLOps
# @CIPHER - SECURITY NOTE: MLflow has CVE-2024-37059 (unsafe deserialization)
# All versions 0.5.0-3.4.0 are affected. No patch available as of Dec 2024.
# MITIGATION: Only load models from trusted sources. See src/services/mlflow_tracker.py
# for safe_load_model() implementation with model verification.
mlflow = "^2.17.0"
optuna = "^4.0.0"
optuna-dashboard = "^0.16.0"

# Vector Store & RAG
chromadb = "^0.5.0"
langchain = "^0.3.0"
langchain-community = "^0.3.0"

# Observability
opentelemetry-api = "^1.27.0"
opentelemetry-sdk = "^1.27.0"
opentelemetry-instrumentation-fastapi = "^0.48b0"
opentelemetry-exporter-jaeger = "^1.21.0"
structlog = "^24.4.0"
prometheus-client = "^0.21.0"

# Utilities
httpx = "^0.27.0"
python-multipart = "^0.0.12"
python-jose = {extras = ["cryptography"], version = "^3.5.0"}
aiofiles = "^24.1.0"
tenacity = "^9.0.0"
passlib = {extras = ["bcrypt"], version = "^1.7.4"}

[tool.poetry.group.dev.dependencies]
pytest = "^8.3.0"
pytest-asyncio = "^0.24.0"
pytest-cov = "^5.0.0"
httpx = "^0.27.0"
ruff = "^0.6.0"
mypy = "^1.11.0"
black = "^24.8.0"
pre-commit = "^3.8.0"
faker = "^28.0.0"
hypothesis = "^6.112.0"

[tool.poetry.group.gpu]
optional = true

[tool.poetry.group.gpu.dependencies]
# GPU-specific dependencies for CUDA-enabled training
# @TENSOR - Used with nvcr.io/nvidia/pytorch:24.09-py3 base image
bitsandbytes = "^0.44.0"
accelerate = "^0.34.0"
peft = "^0.13.0"
# Triton for torch.compile() kernel optimization (auto-installed with NGC container)
triton = {version = "^3.1.0", markers = "sys_platform == 'linux'"}

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.ruff]
target-version = "py311"
line-length = 100
select = [
    "E",   # pycodestyle errors
    "W",   # pycodestyle warnings
    "F",   # Pyflakes
    "I",   # isort
    "C",   # flake8-comprehensions
    "B",   # flake8-bugbear
    "UP",  # pyupgrade
]
ignore = ["E501", "B008", "C901"]

[tool.mypy]
python_version = "3.12"
strict = true
ignore_missing_imports = true

[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = ["tests"]
addopts = "-v --cov=src --cov-report=term-missing"
